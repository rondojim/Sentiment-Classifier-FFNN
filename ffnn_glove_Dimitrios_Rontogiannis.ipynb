{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import dataset '**imdb-reviews.csv**' from google drive and use pandas to parse.\n"
      ],
      "metadata": {
        "id": "d-KXyqtJFzMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "cn2XuUvfHxgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAH4Rvv8FwZY"
      },
      "outputs": [],
      "source": [
        "dataset_path = '/content/drive/MyDrive/imdb-reviews.csv'\n",
        "testset_path = None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import pandas\n",
        "import re\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.corpus import wordnet\n",
        "nltk.download('omw-1.4')\n",
        "from textblob import Word \n",
        "from collections import Counter\n",
        "import operator\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "import random\n"
      ],
      "metadata": {
        "id": "sGPugTvBF7BQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pandas.read_csv(dataset_path, sep='\\t', engine='python')"
      ],
      "metadata": {
        "id": "TTLZfNSJGtxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "_k-CbPYCF8wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "eieV28v_F-_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clear review comments. Remove:\n",
        "\n",
        "    HTML\n",
        "    Numbers\n",
        "    Punctuation\n",
        "    Uppercase\n",
        "    Stopwords\n",
        "    Lemmatization\n",
        "\n"
      ],
      "metadata": {
        "id": "UKJEIonSGBqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# HTML\n",
        "\n",
        "def remove_html(text):\n",
        "  return  re.sub('<.*?>', '', text)\n",
        "  \n",
        "def clean_html(df):\n",
        "  df['review'] = df['review'].apply(remove_html)\n",
        "  print(df.head())\n",
        "  return df"
      ],
      "metadata": {
        "id": "D-AIME7qI_bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Numbers\n",
        "\n",
        "def clean_numbers(df):\n",
        "  df['review'] = df['review'].str.replace(r'\\d+', '', regex=True)\n",
        "  print(df.head())\n",
        "  return df"
      ],
      "metadata": {
        "id": "ijrqSPxbJALo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Punctuation\n",
        "\n",
        "def clean_punctuation(df):\n",
        "  df['review'] = df['review'].str.replace(r'[^\\w\\s]+', '', regex=True)\n",
        "  print(df.head())\n",
        "  return df"
      ],
      "metadata": {
        "id": "lLd30PUhJBqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Uppercase\n",
        "\n",
        "def clean_uppercase(df):\n",
        "  df['review'] = df['review'].str.lower()\n",
        "  print(df.head())\n",
        "  return df"
      ],
      "metadata": {
        "id": "92opytkPJDh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we perform the other removals we need to tokenize the words"
      ],
      "metadata": {
        "id": "7uwv_aQpJHOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "\n",
        "def clean_tokenize(df):\n",
        "  df['review'] = df['review'].apply(word_tokenize)\n",
        "  print(df.head())\n",
        "  return df"
      ],
      "metadata": {
        "id": "TWHPM-k3JHy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stopwords\n",
        "\n",
        "pattern = stopwords.words('english')\n",
        "\n",
        "def clean_stopwords(df):\n",
        "  df['review'] = df['review'].apply(lambda words: [w for w in words if w not in pattern])\n",
        "  print(df.head())\n",
        "  return df"
      ],
      "metadata": {
        "id": "kAWE8adXJKUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatization\n",
        "\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "def clean_lemmatize(df):\n",
        "  df['review'] = df['review'].apply(lambda word: [lemmatizer.lemmatize(lemmatizer.lemmatize(lemmatizer.lemmatize(lemmatizer.lemmatize(lemmatizer.lemmatize(w, 'n'), 'a'), 'v'), 'r'), 's') for w in word])\n",
        "  print(df.head())\n",
        "  return df"
      ],
      "metadata": {
        "id": "N049RsACJO00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we transform rating to 0 for negative (values in range [0, 4.0]) and 1 for positive (values in range [7.0, 10.0])"
      ],
      "metadata": {
        "id": "XszxZZKJJTgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_scale(df):\n",
        "  df['rating'] = df['rating'].apply(lambda x: 0 if x <= 4.0 else 1)\n",
        "  print(df.head())\n",
        "  return df"
      ],
      "metadata": {
        "id": "M7zh4fIKJVbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we remove some rare words:"
      ],
      "metadata": {
        "id": "69dij-A4JZ-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rarewords\n",
        "\n",
        "def clean_rarewords(df):\n",
        "  temp = df['review'].apply(lambda l: [item for item in l])\n",
        "  flat_list = [item for sublist in temp for item in sublist]\n",
        "  counter_list = Counter(flat_list).most_common()\n",
        "  final_list_desc = counter_list[:10]\n",
        "  final_list_asc  = counter_list[-10:]\n",
        "  only_first = [x for x,y in final_list_desc]\n",
        "  only_last  = [x for x,y in final_list_asc]\n",
        "\n",
        "  df['review'] = df['review'].apply(lambda words: [x for x in words if (x not in only_first) and (x not in only_last)])\n",
        "  print(df.head())\n",
        "  return df"
      ],
      "metadata": {
        "id": "MmXly3pqJdpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform(df):\n",
        "  df = clean_html(df)\n",
        "  df = clean_numbers(df)\n",
        "  df = clean_punctuation(df)\n",
        "  df = clean_uppercase(df)\n",
        "  df = clean_tokenize(df)\n",
        "  df = clean_stopwords(df)\n",
        "  df = clean_lemmatize(df)\n",
        "  df = clean_scale(df)\n",
        "  df = clean_rarewords(df)\n",
        "  return df"
      ],
      "metadata": {
        "id": "zDFpTjDKJf4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = transform(df)"
      ],
      "metadata": {
        "id": "oMERUtaMJhoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we split the dataset into training, validation, and testing sets"
      ],
      "metadata": {
        "id": "ESf8HvPhLMOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['review'].apply(lambda x: ' '.join(x))\n",
        "Y = df['rating']\n",
        "\n",
        "trainX, testX, trainY, testY = train_test_split(X, Y, train_size=0.80, random_state=13)\n",
        "testX, valX, testY, valY = train_test_split(testX, testY, train_size=0.5, random_state=13)\n",
        "\n",
        "print(len(trainX))\n",
        "print(len(valX))\n",
        "print(len(testX))"
      ],
      "metadata": {
        "id": "YpdwwcnvLZZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we convert the reviews into numbers using the Glove model."
      ],
      "metadata": {
        "id": "m7BsanzCN-68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip  \n",
        "!unzip glove.6B.zip  "
      ],
      "metadata": {
        "id": "fPrO3iZ8V06l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_dict = {}\n",
        "with open('glove.6B.300d.txt', \"r\") as file:  \n",
        "    for line in file:      \n",
        "      word, coefs = line.split(maxsplit=1)\n",
        "      coefs = np.fromstring(coefs, dtype=float, sep=\" \")\n",
        "      glove_dict[word] = coefs\n",
        "\n",
        "print(\"Dictionary size: \", len(glove_dict))\n"
      ],
      "metadata": {
        "id": "-EZRfXZwYczY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Example:\\n\");\n",
        "print(\"good -> \", glove_dict[\"good\"])"
      ],
      "metadata": {
        "id": "wAyBw4xZbs5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def glove_dataframe(df):\n",
        "  recognized_words = 0\n",
        "  total_words = 0\n",
        "  review_vectors = []\n",
        "\n",
        "  for i, row in enumerate(df):\n",
        "    words = str(row).split(' ')\n",
        "    cur_words = len(words)\n",
        "    total_words += cur_words\n",
        "    coefs = np.zeros(300)\n",
        "\n",
        "    for j, word in enumerate(words):\n",
        "      if word in glove_dict:\n",
        "        recognized_words += 1\n",
        "        cur_coefs = glove_dict[word]\n",
        "        \n",
        "        for idx, c in enumerate(cur_coefs):\n",
        "          coefs[idx] += c\n",
        "    \n",
        "    for idx, c in enumerate(coefs):\n",
        "      coefs[idx] = c / cur_words\n",
        "    \n",
        "    review_vectors.append(coefs)\n",
        "  \n",
        "  return np.array(review_vectors), recognized_words, total_words\n",
        "      "
      ],
      "metadata": {
        "id": "S0Q3oA_1_AY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_trainX, recognized_words, total_words = glove_dataframe(trainX)\n"
      ],
      "metadata": {
        "id": "ENQx3J8HB5JL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recognized words:  3754726  Total words:  3922278  Ratio:  0.9572819672649414\n",
        "\n",
        "Recognized words:  473874  Total words:  494881  Ratio:  0.9575514113493951\n",
        "\n",
        "Recognized words:  469472  Total words:  489972  Ratio:  0.9581608744989509\n"
      ],
      "metadata": {
        "id": "Y4PAEZeq2VON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Recognized words: \", recognized_words, \" Total words: \", total_words, \" Ratio: \", recognized_words / total_words)"
      ],
      "metadata": {
        "id": "6i2ZdE6XHAsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_valX, recognized_words, total_words = glove_dataframe(valX)\n"
      ],
      "metadata": {
        "id": "tSUwit8jHW4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Recognized words: \", recognized_words, \" Total words: \", total_words, \" Ratio: \", recognized_words / total_words)"
      ],
      "metadata": {
        "id": "3IwPq-BTHeYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_testX, recognized_words, total_words = glove_dataframe(testX)\n"
      ],
      "metadata": {
        "id": "yTo1y8kPHiHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Recognized words: \", recognized_words, \" Total words: \", total_words, \" Ratio: \", recognized_words / total_words)"
      ],
      "metadata": {
        "id": "8obpbFm8Hr7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will convert datasets and labels to tensors"
      ],
      "metadata": {
        "id": "UZmnpCRqUPO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "glove_trainX = torch.tensor(glove_trainX)\n",
        "trainY = torch.squeeze(torch.from_numpy(trainY.to_numpy()).float())\n",
        "glove_valX = torch.tensor(glove_valX)\n",
        "valY = torch.squeeze(torch.from_numpy(valY.to_numpy()).float())\n",
        "glove_testX = torch.tensor(glove_testX)\n",
        "testY = torch.squeeze(torch.from_numpy(testY.to_numpy()).float())"
      ],
      "metadata": {
        "id": "sJjDjLKxUWXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will build the Feed Forward Neural Network"
      ],
      "metadata": {
        "id": "pnfP5kiwX8tI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self, D_in, H1, H2, H3, D_out):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        self.linear1 = nn.Linear(D_in, H1)\n",
        "        self.linear2 = nn.Linear(H1, H2)\n",
        "        self.linear3 = nn.Linear(H2, H3)\n",
        "        self.linear4 = nn.Linear(H3, D_out)\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "  \n",
        "  def forward(self, x):\n",
        "        h1 = self.linear1(x)\n",
        "        h2 = self.linear2(h1)\n",
        "        h3 = self.linear3(h2)\n",
        "        h4 = self.linear4(h3)\n",
        "        out = self.sigmoid(h4)\n",
        "        return out"
      ],
      "metadata": {
        "id": "sjlipnBUYC4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_classification_report(model):\n",
        "  x_batch = torch.squeeze(glove_testX.to(torch.float32))\n",
        "  y_pred = torch.squeeze(model(x_batch))\n",
        "  y_pred = torch.round(y_pred)\n",
        "\n",
        "  print(classification_report(testY.detach().numpy(), y_pred.detach().numpy()))\n"
      ],
      "metadata": {
        "id": "qcyAlATJkjEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_roc_curve(model):\n",
        "  x_batch = torch.squeeze(glove_testX.to(torch.float32))\n",
        "  y_pred = torch.squeeze(model(x_batch))\n",
        "  y_pred = y_pred.detach().numpy()\n",
        "  y_real = testY.detach().numpy()\n",
        "  false_positive_rate, true_positive_rate, threshold = roc_curve(y_real, y_pred)\n",
        "  print(\"Print roc_auc score: \", roc_auc_score(y_real, y_pred))\n",
        "\n",
        "  plt.plot(false_positive_rate, true_positive_rate)\n",
        "  plt.plot([0, 1], ls=\"--\")\n",
        "  plt.plot([0, 0], [1, 0] , c=\".7\")\n",
        "  plt.plot([1, 1] , c=\".7\")\n",
        "\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "8ALJg56uwYxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_test_hyperparameters(H1_, H2_, H3_, learning_rate_, batch_size_, epoch_, optimizer_, loss_func_):\n",
        "  D_in = glove_trainX.shape[1]\n",
        "  H1 = H1_\n",
        "  H2 = H2_\n",
        "  H3 = H3_\n",
        "  D_out = 1\n",
        "\n",
        "  model = Net(D_in, H1, H2, H3, D_out)\n",
        "  loss_func = loss_func_\n",
        "  learning_rate = learning_rate_\n",
        "  optimizer = optimizer_(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  dataset = torch.utils.data.TensorDataset(glove_trainX, trainY)\n",
        "  dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size_, shuffle=True)\n",
        "\n",
        "  dataset1 = torch.utils.data.TensorDataset(glove_valX, valY)\n",
        "  dataloader1 = torch.utils.data.DataLoader(dataset1, batch_size=len(glove_valX), shuffle=True)\n",
        "\n",
        "  avg_loss = []\n",
        "  avg_acc = []\n",
        "  val_loss = []\n",
        "  val_acc = []\n",
        "\n",
        "  for epoch in range(epoch_):\n",
        "    batch_losses = []\n",
        "    batch_acc = []\n",
        "\n",
        "    for x_batch, y_batch in dataloader:\n",
        "\n",
        "      x_batch = torch.squeeze(x_batch.to(torch.float32))\n",
        "      y_pred = torch.squeeze(model(x_batch))\n",
        "      loss = loss_func(y_pred, y_batch)\n",
        "\n",
        "      batch_losses.append(loss.item())\n",
        "      y_pred = torch.round(y_pred)\n",
        "      predicted = (y_pred == y_batch).float()\n",
        "      if len(predicted) > 0:\n",
        "        batch_acc.append(predicted.sum() / len(predicted))\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    avg_loss.append(sum(batch_losses)/len(dataloader))\n",
        "    avg_acc.append(sum(batch_acc) / len(batch_acc))\n",
        "    \n",
        "\n",
        "    x_batch = torch.squeeze(glove_valX.to(torch.float32))\n",
        "    y_pred = torch.squeeze(model(x_batch))\n",
        "    loss = loss_func(y_pred, valY)\n",
        "\n",
        "    val_loss.append(loss.item())\n",
        "    y_pred = torch.round(y_pred)\n",
        "    predicted = (y_pred == valY).float()\n",
        "    if len(predicted) > 0:\n",
        "      val_acc.append(predicted.sum() / len(predicted))\n",
        "\n",
        "  return model, avg_loss, avg_acc, val_loss, val_acc"
      ],
      "metadata": {
        "id": "hlQCpa_REdyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss_accuracy(epoch, avg_loss, val_loss, avg_acc, val_acc):\n",
        "  print(\"Batches average loss: \", sum(avg_loss) / len(avg_loss))\n",
        "  print(\"Batches average acc: \", float(sum(avg_acc) / len(avg_acc)))\n",
        "  print(\"Validation average loss: \", sum(val_loss) / len(val_loss))\n",
        "  print(\"Validation average acc: \", float(sum(val_acc) / len(val_acc)))\n",
        "  \n",
        "  plt.plot(range(100), avg_loss, marker=\"x\")\n",
        "  plt.plot(range(100), val_loss, marker=\"*\")\n",
        "  plt.legend([\"Training loss\", \"Validation loss\"])\n",
        "  plt.xlabel(\"epoch\")\n",
        "  plt.ylabel(\"loss\")\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(range(100), avg_acc, marker=\"x\")\n",
        "  plt.plot(range(100), val_acc, marker=\"*\")\n",
        "  plt.legend([\"Training accuracy\", \"Validation accuracy\"])\n",
        "  plt.xlabel(\"epoch\")\n",
        "  plt.ylabel(\"loss\")\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "M9LjwG04jjZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will experiment to make it better. We will not use grid search because of the time complexity"
      ],
      "metadata": {
        "id": "E1xK4f_tSwBp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hidden layer sizes:"
      ],
      "metadata": {
        "id": "fr6bo02SS7St"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(8):\n",
        "#   h1 = random.randint(1, 600)\n",
        "#   h2 = random.randint(1, h1)\n",
        "#   h3 = random.randint(1, h2)\n",
        "\n",
        "#   print(\"h1, h2, h3 = \", h1, h2, h3)\n",
        "#   model, avg_loss, avg_acc, val_loss, val_acc = train_and_test_hyperparameters(h1, h2, h3, 0.005, 64, 100, torch.optim.SGD)\n",
        "#   plot_loss_accuracy(range(100), avg_loss, val_loss, avg_acc, val_acc)\n",
        "#   get_roc_curve(model)\n",
        "#   get_classification_report(model)\n",
        "\n"
      ],
      "metadata": {
        "id": "KqbOgFxkTCLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have no significant improvement so we will stick with the old values."
      ],
      "metadata": {
        "id": "zOkJvRIuqbbB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best hidden layer sizes:"
      ],
      "metadata": {
        "id": "Gc1K-4qRWZi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_h1 = 256\n",
        "best_h2 = 128\n",
        "best_h3 = 64\n"
      ],
      "metadata": {
        "id": "j6Ndv4r_WW1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will test learning rate:"
      ],
      "metadata": {
        "id": "thHvWijlV4fW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# learning_rate = [1, 0.5, 0.1, 0.05, 0.01, 0.005, 0.001]\n",
        "\n",
        "# for lr in learning_rate:\n",
        "\n",
        "#   model, avg_loss, avg_acc, val_loss, val_acc = train_and_test_hyperparameters(best_h1, best_h2, best_h3, lr, 64, 100, torch.optim.SGD)\n",
        "#   plot_loss_accuracy(range(100), avg_loss, val_loss, avg_acc, val_acc)\n",
        "#   get_roc_curve(model)\n",
        "#   get_classification_report(model)"
      ],
      "metadata": {
        "id": "wj-LgCW1V97Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that we have good results with learning rate 0.01, 0.005, and 0.001. We will use 0.005 for our best learning rate."
      ],
      "metadata": {
        "id": "GcTelBVBW9D1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_lr = 0.01"
      ],
      "metadata": {
        "id": "9NV-kO3MXBiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will test batch size:"
      ],
      "metadata": {
        "id": "D0_X6uoZWx4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size = [2, 4, 8, 16, 32, 64, 128, 256]\n",
        "\n",
        "# for batch in batch_size:\n",
        "\n",
        "#   model, avg_loss, avg_acc, val_loss, val_acc = train_and_test_hyperparameters(best_h1, best_h2, best_h3, best_lr, batch, 100, torch.optim.SGD)\n",
        "#   plot_loss_accuracy(range(100), avg_loss, val_loss, avg_acc, val_acc)\n",
        "#   get_roc_curve(model)\n",
        "#   get_classification_report(model)"
      ],
      "metadata": {
        "id": "pNeo4QIrWzwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Is seems that batch size does not change accuracy a lot. We will use as best batch_size: 128"
      ],
      "metadata": {
        "id": "PIej6JsSXKvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_batch = 128"
      ],
      "metadata": {
        "id": "Bp212t2nXMJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will test different optimizers"
      ],
      "metadata": {
        "id": "wyo22OfIXQyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizers = [torch.optim.Adadelta, torch.optim.ASGD, torch.optim.Adamax, torch.optim.Rprop, torch.optim.SGD]\n",
        "\n",
        "# for optimizer in optimizers:\n",
        "\n",
        "#   model, avg_loss, avg_acc, val_loss, val_acc = train_and_test_hyperparameters(best_h1, best_h2, best_h3, best_lr, best_batch, 100, optimizer)\n",
        "#   plot_loss_accuracy(range(100), avg_loss, val_loss, avg_acc, val_acc)\n",
        "#   get_roc_curve(model)\n",
        "#   get_classification_report(model)"
      ],
      "metadata": {
        "id": "FFiv-H5_XTSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best optimizer:"
      ],
      "metadata": {
        "id": "oDsARQ5oYfML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_optimizer = torch.optim.Adadelta"
      ],
      "metadata": {
        "id": "oU5WRH6XYgyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func_ = [nn.L1Loss(), nn.MSELoss(), nn.CrossEntropyLoss(), nn.BCELoss(), nn.BCEWithLogitsLoss(), nn.SoftMarginLoss()]"
      ],
      "metadata": {
        "id": "V1sTlRjtVnoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for loss_func__ in loss_func_:\n",
        "#   model, avg_loss, avg_acc, val_loss, val_acc = train_and_test_hyperparameters(best_h1, best_h2, best_h3, best_lr, best_batch, 100, best_optimizer, loss_func__)\n",
        "#   plot_loss_accuracy(range(100), avg_loss, val_loss, avg_acc, val_acc)\n",
        "#   get_roc_curve(model)\n",
        "#   get_classification_report(model)"
      ],
      "metadata": {
        "id": "m9Z5z5mtWFjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_loss_func = nn.BCELoss()"
      ],
      "metadata": {
        "id": "-KOXHfpbao5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_testX_ = glove_testX\n",
        "testY_ = testY\n",
        "\n",
        "if testset_path is not None:\n",
        "  df_test = pandas.read_csv(testset_path, sep='\\t', engine='python')\n",
        "  df_test = transform(df_test)\n",
        "  X_test = df_test['review'].apply(lambda x: ' '.join(x))\n",
        "  Y_test = df_test['rating']\n",
        "\n",
        "  glove_testX__, recognized_words, total_words = glove_dataframe(X_test)\n",
        "  testY__ = Y_test\n",
        "\n",
        "  glove_testX_ = torch.tensor(glove_testX__)\n",
        "  testY_ = torch.squeeze(torch.from_numpy(testY__.to_numpy()).float())\n",
        "\n",
        "glove_testX = glove_testX_\n",
        "testY = testY_\n",
        "\n"
      ],
      "metadata": {
        "id": "ilZHJuSNbjrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, avg_loss, avg_acc, val_loss, val_acc = train_and_test_hyperparameters(best_h1, best_h2, best_h3, best_lr, best_batch, 100, best_optimizer, best_loss_func)\n",
        "plot_loss_accuracy(range(100), avg_loss, val_loss, avg_acc, val_acc)\n",
        "get_roc_curve(model)\n",
        "get_classification_report(model)"
      ],
      "metadata": {
        "id": "Swd7H51Mv2LA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}